{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7Tccu9fSbCRx",
      "metadata": {
        "id": "7Tccu9fSbCRx"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3VELCWU_cxv",
      "metadata": {
        "id": "a3VELCWU_cxv"
      },
      "source": [
        "First, we need to install packages beyond those pre-installed in Colab in order to run Florence-2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UrhfCxvgOOWf",
      "metadata": {
        "id": "UrhfCxvgOOWf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install timm flash_attn einops;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56B28fGytdtl",
      "metadata": {
        "id": "56B28fGytdtl"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "git clone https://github.com/AssemblyAI-Community/florence-2\n",
        "mv florence-2/** .\n",
        "rm -rf ./florence-2/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BHXKb_rNhomg",
      "metadata": {
        "id": "BHXKb_rNhomg"
      },
      "outputs": [],
      "source": [
        "!python -m pip install --upgrade transformers==4.53.1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a5afc4f-7540-4dce-8d18-ad74db6a22b7",
      "metadata": {
        "id": "3a5afc4f-7540-4dce-8d18-ad74db6a22b7"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM\n",
        "from PIL import Image\n",
        "import requests\n",
        "\n",
        "import utils\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qQ6yRn_MiJ0i",
      "metadata": {
        "id": "qQ6yRn_MiJ0i"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login --token \"add_your_huggingface_token_here\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oHzpQZ3JU8KP",
      "metadata": {
        "id": "oHzpQZ3JU8KP"
      },
      "outputs": [],
      "source": [
        "!ngrok config add-authtoken \"add_your_ngrok_token_here\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "998b356b-630d-4b89-8139-1995e31822e7",
      "metadata": {
        "id": "998b356b-630d-4b89-8139-1995e31822e7"
      },
      "outputs": [],
      "source": [
        "model_id = 'microsoft/Florence-2-large'\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True).eval().cuda()\n",
        "processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mX2BeW8MCi_3",
      "metadata": {
        "id": "mX2BeW8MCi_3"
      },
      "outputs": [],
      "source": [
        "utils.set_model_info(model, processor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QEmDjSYFVNuW",
      "metadata": {
        "id": "QEmDjSYFVNuW"
      },
      "outputs": [],
      "source": [
        "!pkill ngrok || true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jlkS0Ao7ne0c",
      "metadata": {
        "id": "jlkS0Ao7ne0c"
      },
      "outputs": [],
      "source": [
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BcoCHUPoWWlt",
      "metadata": {
        "id": "BcoCHUPoWWlt"
      },
      "outputs": [],
      "source": [
        "!pip install groq pillow fal-client requests flask pyngrok flask-cors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bm4yCBSxWmBw",
      "metadata": {
        "id": "bm4yCBSxWmBw"
      },
      "outputs": [],
      "source": [
        "!pkill ngrok || true\n",
        "!ngrok config add-authtoken 33bfkQRER7AYPl7DUpPLVG4ahtd_3afEGFNzNnGxKfoAuTGZk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lGQMnbf1UZ96",
      "metadata": {
        "id": "lGQMnbf1UZ96"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import glob\n",
        "import requests\n",
        "import threading\n",
        "from PIL import Image, ImageDraw\n",
        "from groq import Groq\n",
        "import fal_client\n",
        "from flask import Flask, request, jsonify, render_template_string, send_file\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "from werkzeug.utils import secure_filename\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# --- CELL 3: Configuration ---\n",
        "# API Keys\n",
        "\n",
        "GROQ_API_KEY = \"paste_Your_GROQ_API_KEY_Here\"\n",
        "\n",
        "# Paths\n",
        "UPLOAD_FOLDER = \"/content/uploads\"\n",
        "MASKS_FOLDER = \"/content/correction_masks\"\n",
        "OUTPUT_DIR = \"/content/fal_corrections\"\n",
        "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}\n",
        "\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "os.makedirs(MASKS_FOLDER, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Initialize Groq client\n",
        "client = Groq(api_key=GROQ_API_KEY)\n",
        "\n",
        "# --- CELL 4: Flask App Setup ---\n",
        "app = Flask(__name__)\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size\n",
        "CORS(app)\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "# --- CELL 5: OCR Validation Function ---\n",
        "def validate_and_correct_ocr(results_task, image_context_description, client):\n",
        "    \"\"\"\n",
        "    Analyze OCR results and identify incorrect text with suggested corrections.\n",
        "    \"\"\"\n",
        "    labels = results_task['labels']\n",
        "    boxes = results_task['quad_boxes']\n",
        "    print(image_context_description)\n",
        "    prompt = f\"\"\"You are an expert OCR validator analyzing text from an image.\n",
        "\n",
        "IMAGE CONTEXT:\n",
        "{image_context_description}\n",
        "\n",
        "EXTRACTED OCR TEXT (in order):\n",
        "{json.dumps(labels, indent=2)}\n",
        "\n",
        "TASK:\n",
        "Identify which texts are incorrect or misspelled, and suggest corrections.\n",
        "Consider the context provided by the user, if the misspelled word does not match with any of the words given by user, then replace it with a sensible and related word of your own.\n",
        "\n",
        "Return ONLY a JSON array with this exact structure:\n",
        "[\n",
        "  {{\n",
        "    \"incorrect_text\": \"exact text from OCR\",\n",
        "    \"suggested_correction\": \"what it should be\",\n",
        "    \"confidence\": \"high/medium/low\",\n",
        "    \"reason\": \"brief explanation\"\n",
        "  }}\n",
        "]\n",
        "\n",
        "Rules:\n",
        "- Only include texts that are clearly wrong or misspelled\n",
        "- Use context clues from the description\n",
        "- Be specific with corrections\n",
        "- Skip texts that are correct\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.2,\n",
        "            max_tokens=2048,\n",
        "        )\n",
        "\n",
        "        result_text = completion.choices[0].message.content.strip()\n",
        "\n",
        "        # Clean JSON from markdown code blocks\n",
        "        if \"```json\" in result_text:\n",
        "            result_text = result_text.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in result_text:\n",
        "            result_text = result_text.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "\n",
        "        parsed = json.loads(result_text)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Error parsing LLM response: {e}\")\n",
        "        print(f\"Raw response: {result_text if 'result_text' in locals() else 'No response'}\")\n",
        "        return []\n",
        "\n",
        "    # Map incorrect labels to their quad boxes\n",
        "    validation_results = []\n",
        "    for item in parsed:\n",
        "        incorrect_text = item['incorrect_text']\n",
        "        if incorrect_text in labels:\n",
        "            idx = labels.index(incorrect_text)\n",
        "            validation_results.append({\n",
        "                \"incorrect_text\": incorrect_text,\n",
        "                \"suggested_correction\": item['suggested_correction'],\n",
        "                \"confidence\": item['confidence'],\n",
        "                \"reason\": item['reason'],\n",
        "                \"quad_box\": boxes[idx],\n",
        "                \"box_index\": idx\n",
        "            })\n",
        "\n",
        "    return validation_results\n",
        "\n",
        "# --- CELL 6: Generate Masks for Incorrect Boxes Only ---\n",
        "def create_correction_masks(image_path, validation_results, output_dir=MASKS_FOLDER):\n",
        "    \"\"\"\n",
        "    Create individual mask images for each incorrect region (white on black).\n",
        "    Returns list of tuples: (mask_path, correction_text, incorrect_text)\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Clear existing masks\n",
        "    for old_mask in glob.glob(os.path.join(output_dir, \"mask_*.png\")):\n",
        "        os.remove(old_mask)\n",
        "\n",
        "    base_img = Image.open(image_path).convert(\"L\")\n",
        "    w, h = base_img.size\n",
        "    mask_info = []\n",
        "\n",
        "    for i, item in enumerate(validation_results, 1):\n",
        "        quad = item[\"quad_box\"]\n",
        "        mask = Image.new(\"L\", (w, h), 0)  # Black background\n",
        "        draw = ImageDraw.Draw(mask)\n",
        "        polygon = [(quad[j], quad[j+1]) for j in range(0, len(quad), 2)]\n",
        "        draw.polygon(polygon, outline=255, fill=255)  # White box\n",
        "\n",
        "        # Create safe filename from suggested correction\n",
        "        safe_text = \"\".join(c if c.isalnum() else \"_\" for c in item[\"suggested_correction\"][:30])\n",
        "        mask_path = os.path.join(output_dir, f\"mask_{i:02d}_{safe_text}.png\")\n",
        "        mask.save(mask_path)\n",
        "\n",
        "        mask_info.append({\n",
        "            \"mask_path\": mask_path,\n",
        "            \"correction_text\": item[\"suggested_correction\"],\n",
        "            \"incorrect_text\": item[\"incorrect_text\"],\n",
        "            \"confidence\": item[\"confidence\"],\n",
        "            \"reason\": item[\"reason\"]\n",
        "        })\n",
        "\n",
        "        print(f\"‚úÖ Created mask {i}: '{item['incorrect_text']}' ‚Üí '{item['suggested_correction']}'\")\n",
        "\n",
        "    return mask_info\n",
        "\n",
        "# --- CELL 7: No separate upload needed ---\n",
        "# The /sequential endpoint handles everything, so we don't need a separate upload function\n",
        "\n",
        "# --- CELL 8: Sequential Correction with ngrok Calligrapher ---\n",
        "def apply_corrections_with_ngrok(source_image_path, mask_info_list, ngrok_url, output_dir=OUTPUT_DIR):\n",
        "    \"\"\"\n",
        "    Sequentially apply corrections using ngrok Calligrapher /sequential endpoint.\n",
        "    The server handles all steps internally using the previous output as the next input.\n",
        "    \"\"\"\n",
        "    # Get original dimensions\n",
        "    with Image.open(source_image_path) as img:\n",
        "        orig_width, orig_height = img.size\n",
        "    print(f\"üìè Original image size: {orig_width}√ó{orig_height}\")\n",
        "\n",
        "    print(f\"\\nüñãÔ∏è Starting sequential corrections for {len(mask_info_list)} boxes...\\n\")\n",
        "\n",
        "    try:\n",
        "        # Prepare mask_info_list for the API\n",
        "        # The server expects mask_url, so we need to ensure masks are accessible\n",
        "        # For now, we'll read mask files and include them in the request\n",
        "\n",
        "        # Prepare the JSON payload\n",
        "        api_mask_info_list = []\n",
        "        for idx, mask_info in enumerate(mask_info_list, start=1):\n",
        "            correction_text = mask_info[\"correction_text\"]\n",
        "            incorrect_text = mask_info[\"incorrect_text\"]\n",
        "            mask_path = mask_info[\"mask_path\"]\n",
        "\n",
        "            print(f\"üîß Step {idx}/{len(mask_info_list)}: '{incorrect_text}' ‚Üí '{correction_text}'\")\n",
        "            print(f\"   Confidence: {mask_info['confidence']}, Reason: {mask_info['reason']}\")\n",
        "\n",
        "            # Note: The /sequential endpoint expects mask_url\n",
        "            # You'll need to either:\n",
        "            # 1. Host masks temporarily and provide URLs, OR\n",
        "            # 2. Modify the server to accept mask files directly\n",
        "\n",
        "            # For this implementation, we'll use individual /generate calls\n",
        "            # since /sequential expects mask_url which we don't have\n",
        "\n",
        "        print(\"\\n‚ö†Ô∏è Using individual /generate calls instead of /sequential\")\n",
        "        print(\"   (because /sequential expects mask_url, not mask files)\")\n",
        "\n",
        "        current_image_path = source_image_path\n",
        "\n",
        "        for idx, mask_info in enumerate(mask_info_list, start=1):\n",
        "            correction_text = mask_info[\"correction_text\"]\n",
        "            incorrect_text = mask_info[\"incorrect_text\"]\n",
        "            mask_path = mask_info[\"mask_path\"]\n",
        "\n",
        "            print(f\"\\n{'='*70}\")\n",
        "            print(f\"üîß Step {idx}/{len(mask_info_list)}: Correcting '{incorrect_text}' ‚Üí '{correction_text}'\")\n",
        "            print(f\"   Confidence: {mask_info['confidence']}\")\n",
        "            print(f\"   Reason: {mask_info['reason']}\")\n",
        "            print(f\"{'='*70}\")\n",
        "\n",
        "            # Create prompt with the CORRECT text\n",
        "            prompt = f\"The text is '{correction_text}'\"\n",
        "            print(f\"üí¨ Prompt: {prompt}\")\n",
        "\n",
        "            # Prepare files and data for ngrok API\n",
        "            with open(current_image_path, 'rb') as img_file, open(mask_path, 'rb') as mask_file:\n",
        "                files = {\n",
        "                    'image_file': img_file,\n",
        "                    'mask_file': mask_file\n",
        "                }\n",
        "                data = {\n",
        "                    'prompt': prompt,\n",
        "                    'num_inference_steps': 50,\n",
        "                    'guidance_scale': 1.0,\n",
        "                    'use_context': True\n",
        "                }\n",
        "\n",
        "                # Call ngrok /generate endpoint\n",
        "                print(f\"üì° Calling {ngrok_url}/generate...\")\n",
        "                response = requests.post(f\"{ngrok_url}/generate\", files=files, data=data, timeout=600)\n",
        "                response.raise_for_status()\n",
        "                result = response.json()\n",
        "\n",
        "            # Extract base64 image and save\n",
        "            image_base64 = result[\"image_base64\"]\n",
        "            print(f\"‚úÖ Generated image received\")\n",
        "\n",
        "            # Decode and save new image\n",
        "            new_image_path = os.path.join(\n",
        "                output_dir,\n",
        "                f\"step_{idx:02d}_{correction_text.replace(' ', '_')[:30]}.png\"\n",
        "            )\n",
        "            img_data = base64.b64decode(image_base64)\n",
        "            with open(new_image_path, \"wb\") as f:\n",
        "                f.write(img_data)\n",
        "\n",
        "            # Verify dimensions\n",
        "            with Image.open(new_image_path) as new_img:\n",
        "                w, h = new_img.size\n",
        "                print(f\"üñºÔ∏è Output size: {w}√ó{h} (expected: {orig_width}√ó{orig_height})\")\n",
        "\n",
        "            # Update source for next iteration\n",
        "            current_image_path = new_image_path\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"‚úÖ COMPLETED! All {len(mask_info_list)} corrections applied.\")\n",
        "        print(f\"üìÅ Final corrected image: {current_image_path}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        return current_image_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during sequential correction: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "# --- CELL 9: Main Pipeline Function ---\n",
        "def run_ocr_correction_pipeline(image_path, image_context_description, results_task):\n",
        "    \"\"\"\n",
        "    Complete pipeline with user-provided context.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üöÄ STARTING OCR CORRECTION PIPELINE\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # STEP 1: Validate OCR and find incorrect texts\n",
        "    print(\"\\nüìã STEP 1: Validating OCR results...\")\n",
        "    validation_results = validate_and_correct_ocr(\n",
        "        results_task,\n",
        "        image_context_description,\n",
        "        client\n",
        "    )\n",
        "\n",
        "    if not validation_results:\n",
        "        print(\"\\n‚úÖ No incorrect OCR text found! Image is perfect.\")\n",
        "        return None, []\n",
        "\n",
        "    print(f\"\\nüîç Found {len(validation_results)} incorrect text(s):\")\n",
        "    for i, item in enumerate(validation_results, 1):\n",
        "        print(f\"  {i}. '{item['incorrect_text']}' ‚Üí '{item['suggested_correction']}' ({item['confidence']})\")\n",
        "\n",
        "    # STEP 2: Generate masks for incorrect boxes only\n",
        "    print(f\"\\nüé≠ STEP 2: Generating {len(validation_results)} correction mask(s)...\")\n",
        "    mask_info_list = create_correction_masks(image_path, validation_results)\n",
        "\n",
        "    # STEP 3: Apply corrections sequentially using Fal API\n",
        "    print(\"\\nüîß STEP 3: Applying corrections with Fal Calligrapher...\")\n",
        "\n",
        "    ngrok_url = \"https://your-ngrok-url.ngrok.io\"  # Your ngrok public URL\n",
        "    final_image_path = apply_corrections_with_ngrok(source_image_path, mask_info_list, ngrok_url)\n",
        "    print(\"\\n‚ú® PIPELINE COMPLETE! ‚ú®\")\n",
        "    return final_image_path, validation_results\n",
        "\n",
        "# --- CELL 10: HTML Template ---\n",
        "HTML_TEMPLATE = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>OCR Correction Service</title>\n",
        "    <style>\n",
        "        * { margin: 0; padding: 0; box-sizing: border-box; }\n",
        "        body {\n",
        "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            min-height: 100vh;\n",
        "            padding: 20px;\n",
        "        }\n",
        "        .container {\n",
        "            max-width: 800px;\n",
        "            margin: 0 auto;\n",
        "            background: white;\n",
        "            border-radius: 20px;\n",
        "            box-shadow: 0 20px 60px rgba(0,0,0,0.3);\n",
        "            padding: 40px;\n",
        "        }\n",
        "        h1 {\n",
        "            color: #667eea;\n",
        "            margin-bottom: 10px;\n",
        "            font-size: 2.5em;\n",
        "        }\n",
        "        .subtitle {\n",
        "            color: #666;\n",
        "            margin-bottom: 30px;\n",
        "            font-size: 1.1em;\n",
        "        }\n",
        "        .form-group {\n",
        "            margin-bottom: 25px;\n",
        "        }\n",
        "        label {\n",
        "            display: block;\n",
        "            margin-bottom: 8px;\n",
        "            font-weight: 600;\n",
        "            color: #333;\n",
        "        }\n",
        "        input[type=\"file\"] {\n",
        "            width: 100%;\n",
        "            padding: 12px;\n",
        "            border: 2px dashed #667eea;\n",
        "            border-radius: 10px;\n",
        "            cursor: pointer;\n",
        "            transition: all 0.3s;\n",
        "        }\n",
        "        input[type=\"file\"]:hover {\n",
        "            border-color: #764ba2;\n",
        "            background: #f8f9ff;\n",
        "        }\n",
        "        textarea {\n",
        "            width: 100%;\n",
        "            padding: 15px;\n",
        "            border: 2px solid #e0e0e0;\n",
        "            border-radius: 10px;\n",
        "            font-size: 14px;\n",
        "            font-family: inherit;\n",
        "            resize: vertical;\n",
        "            min-height: 150px;\n",
        "            transition: border-color 0.3s;\n",
        "        }\n",
        "        textarea:focus {\n",
        "            outline: none;\n",
        "            border-color: #667eea;\n",
        "        }\n",
        "        button {\n",
        "            width: 100%;\n",
        "            padding: 15px;\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 10px;\n",
        "            font-size: 16px;\n",
        "            font-weight: 600;\n",
        "            cursor: pointer;\n",
        "            transition: transform 0.2s;\n",
        "        }\n",
        "        button:hover {\n",
        "            transform: translateY(-2px);\n",
        "        }\n",
        "        button:disabled {\n",
        "            opacity: 0.6;\n",
        "            cursor: not-allowed;\n",
        "        }\n",
        "        #status {\n",
        "            margin-top: 20px;\n",
        "            padding: 15px;\n",
        "            border-radius: 10px;\n",
        "            display: none;\n",
        "        }\n",
        "        .status-processing {\n",
        "            background: #fff3cd;\n",
        "            color: #856404;\n",
        "            border: 2px solid #ffeeba;\n",
        "        }\n",
        "        .status-success {\n",
        "            background: #d4edda;\n",
        "            color: #155724;\n",
        "            border: 2px solid #c3e6cb;\n",
        "        }\n",
        "        .status-error {\n",
        "            background: #f8d7da;\n",
        "            color: #721c24;\n",
        "            border: 2px solid #f5c6cb;\n",
        "        }\n",
        "        #result {\n",
        "            margin-top: 30px;\n",
        "            display: none;\n",
        "        }\n",
        "        .result-image {\n",
        "            width: 100%;\n",
        "            border-radius: 10px;\n",
        "            margin: 20px 0;\n",
        "            box-shadow: 0 5px 15px rgba(0,0,0,0.2);\n",
        "        }\n",
        "        .corrections-list {\n",
        "            background: #f8f9ff;\n",
        "            padding: 20px;\n",
        "            border-radius: 10px;\n",
        "            margin-top: 20px;\n",
        "        }\n",
        "        .correction-item {\n",
        "            padding: 12px;\n",
        "            margin: 10px 0;\n",
        "            background: white;\n",
        "            border-left: 4px solid #667eea;\n",
        "            border-radius: 5px;\n",
        "        }\n",
        "        .download-btn {\n",
        "            display: inline-block;\n",
        "            padding: 12px 30px;\n",
        "            background: #28a745;\n",
        "            color: white;\n",
        "            text-decoration: none;\n",
        "            border-radius: 8px;\n",
        "            margin-top: 15px;\n",
        "            transition: background 0.3s;\n",
        "        }\n",
        "        .download-btn:hover {\n",
        "            background: #218838;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <h1>üî§ OCR Correction Service</h1>\n",
        "        <p class=\"subtitle\">Upload an image and describe its context for intelligent OCR correction</p>\n",
        "\n",
        "        <form id=\"uploadForm\" enctype=\"multipart/form-data\">\n",
        "            <div class=\"form-group\">\n",
        "                <label for=\"image\">üì∑ Select Image (PNG, JPG)</label>\n",
        "                <input type=\"file\" id=\"image\" name=\"image\" accept=\".png,.jpg,.jpeg\" required>\n",
        "            </div>\n",
        "\n",
        "            <div class=\"form-group\">\n",
        "                <label for=\"context\">üìù Image Context Description</label>\n",
        "                <textarea id=\"context\" name=\"context\" placeholder=\"Describe the image context. For example:&#10;&#10;This is a fashion magazine cover featuring Tom Cruise.&#10;- Main magazine title: 'FASHION' (large, at the top)&#10;- Primary headline: 'CRUISE CONTROL'&#10;- Subheadings include fashion trends and watch guides\" required></textarea>\n",
        "            </div>\n",
        "\n",
        "            <button type=\"submit\" id=\"submitBtn\">\n",
        "                üöÄ Process Image\n",
        "            </button>\n",
        "        </form>\n",
        "\n",
        "        <div id=\"status\"></div>\n",
        "        <div id=\"result\"></div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        document.getElementById('uploadForm').addEventListener('submit', async (e) => {\n",
        "            e.preventDefault();\n",
        "\n",
        "            const formData = new FormData();\n",
        "            const imageFile = document.getElementById('image').files[0];\n",
        "            const context = document.getElementById('context').value;\n",
        "\n",
        "            formData.append('image', imageFile);\n",
        "            formData.append('context', context);\n",
        "\n",
        "            const statusDiv = document.getElementById('status');\n",
        "            const resultDiv = document.getElementById('result');\n",
        "            const submitBtn = document.getElementById('submitBtn');\n",
        "\n",
        "            // Show processing status\n",
        "            statusDiv.style.display = 'block';\n",
        "            statusDiv.className = 'status-processing';\n",
        "            statusDiv.innerHTML = '‚è≥ Processing your image... This may take a few minutes.';\n",
        "            submitBtn.disabled = true;\n",
        "            resultDiv.style.display = 'none';\n",
        "\n",
        "            try {\n",
        "                const response = await fetch('/api/correct', {\n",
        "                    method: 'POST',\n",
        "                    body: formData\n",
        "                });\n",
        "\n",
        "                const data = await response.json();\n",
        "\n",
        "                if (data.success) {\n",
        "                    statusDiv.className = 'status-success';\n",
        "                    statusDiv.innerHTML = '‚úÖ Processing complete!';\n",
        "\n",
        "                    let resultHTML = '<h2>Results</h2>';\n",
        "\n",
        "                    if (data.corrections && data.corrections.length > 0) {\n",
        "                        resultHTML += `<p><strong>Found ${data.corrections.length} correction(s):</strong></p>`;\n",
        "                        resultHTML += '<div class=\"corrections-list\">';\n",
        "                        data.corrections.forEach((corr, idx) => {\n",
        "                            resultHTML += `\n",
        "                                <div class=\"correction-item\">\n",
        "                                    <strong>${idx + 1}.</strong> \"${corr.incorrect_text}\" ‚Üí \"${corr.suggested_correction}\"<br>\n",
        "                                    <small><em>${corr.reason} (${corr.confidence} confidence)</em></small>\n",
        "                                </div>\n",
        "                            `;\n",
        "                        });\n",
        "                        resultHTML += '</div>';\n",
        "\n",
        "                        if (data.final_image_url) {\n",
        "                            resultHTML += `\n",
        "                                <img src=\"${data.final_image_url}\" class=\"result-image\" alt=\"Corrected Image\">\n",
        "                                <a href=\"${data.final_image_url}\" class=\"download-btn\" download>üì• Download Corrected Image</a>\n",
        "                            `;\n",
        "                        }\n",
        "                    } else {\n",
        "                        resultHTML += '<p>No corrections needed - the image is already perfect! ‚ú®</p>';\n",
        "                    }\n",
        "\n",
        "                    resultDiv.innerHTML = resultHTML;\n",
        "                    resultDiv.style.display = 'block';\n",
        "\n",
        "                } else {\n",
        "                    statusDiv.className = 'status-error';\n",
        "                    statusDiv.innerHTML = `‚ùå Error: ${data.error || 'Unknown error occurred'}`;\n",
        "                }\n",
        "\n",
        "            } catch (error) {\n",
        "                statusDiv.className = 'status-error';\n",
        "                statusDiv.innerHTML = `‚ùå Error: ${error.message}`;\n",
        "            } finally {\n",
        "                submitBtn.disabled = false;\n",
        "            }\n",
        "        });\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# --- CELL 11: Flask Routes ---\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template_string(HTML_TEMPLATE)\n",
        "\n",
        "@app.route('/api/correct', methods=['POST'])\n",
        "def correct_image():\n",
        "    \"\"\"\n",
        "    API endpoint to process image with user-provided context.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Validate request\n",
        "        if 'image' not in request.files:\n",
        "            return jsonify({'success': False, 'error': 'No image file provided'}), 400\n",
        "\n",
        "        if 'context' not in request.form:\n",
        "            return jsonify({'success': False, 'error': 'No context description provided'}), 400\n",
        "\n",
        "        file = request.files['image']\n",
        "        context_description = request.form['context']\n",
        "\n",
        "        if file.filename == '':\n",
        "            return jsonify({'success': False, 'error': 'No file selected'}), 400\n",
        "\n",
        "        if not allowed_file(file.filename):\n",
        "            return jsonify({'success': False, 'error': 'Invalid file type. Use PNG, JPG, or JPEG'}), 400\n",
        "\n",
        "        # Save uploaded file\n",
        "        filename = secure_filename(file.filename)\n",
        "        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
        "        file.save(filepath)\n",
        "\n",
        "        # Run OCR (you'll need to integrate your actual OCR tool here)\n",
        "        # For now, this is a placeholder - replace with your actual OCR implementation\n",
        "        print(\"üîç Running OCR on uploaded image...\")\n",
        "\n",
        "        # YOU NEED TO ADD YOUR OCR IMPLEMENTATION HERE\n",
        "        # This should use your utils.run_example or similar function\n",
        "        # Example placeholder:\n",
        "        # from your_ocr_module import utils\n",
        "        image = Image.open(filepath).convert(\"RGB\")\n",
        "        task = utils.TaskType.OCR_WITH_REGION\n",
        "        results = utils.run_example(task, image)\n",
        "        results_task = results[task]\n",
        "\n",
        "        # PLACEHOLDER - Replace with actual OCR results\n",
        "\n",
        "\n",
        "        # Run correction pipeline\n",
        "        final_image_path, corrections = run_ocr_correction_pipeline(\n",
        "            filepath,incc\n",
        "            context_description,\n",
        "            results_task\n",
        "        )\n",
        "\n",
        "        # Prepare response\n",
        "        if final_image_path:\n",
        "            return jsonify({\n",
        "                'success': True,\n",
        "                'final_image_url': f'/output/{os.path.basename(final_image_path)}',\n",
        "                'corrections': corrections,\n",
        "                'total_corrections': len(corrections)\n",
        "            })\n",
        "        else:\n",
        "            return jsonify({\n",
        "                'success': True,\n",
        "                'corrections': [],\n",
        "                'total_corrections': 0,\n",
        "                'message': 'No corrections needed'\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return jsonify({'success': False, 'error': str(e)}), 500\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z6g7iaJMWvw1",
      "metadata": {
        "id": "Z6g7iaJMWvw1"
      },
      "outputs": [],
      "source": [
        "@app.route('/output/<filename>')\n",
        "def serve_output(filename):\n",
        "    \"\"\"Serve corrected images\"\"\"\n",
        "    return send_file(os.path.join(OUTPUT_DIR, filename))\n",
        "\n",
        "# --- CELL 12: Start Server with Ngrok ---\n",
        "def start_server():\n",
        "    \"\"\"Start Flask server with ngrok tunnel\"\"\"\n",
        "    port = 5000\n",
        "\n",
        "    # Start ngrok tunnel\n",
        "    public_url = ngrok.connect(port)\n",
        "    print('\\n' + '='*70)\n",
        "    print('üåê OCR CORRECTION SERVICE STARTED')\n",
        "    print('='*70)\n",
        "    print(f'üîó Public URL: {public_url}')\n",
        "    print(f'üè† Local URL: http://localhost:{port}')\n",
        "    print('='*70)\n",
        "    print('\\nüìù Usage:')\n",
        "    print('1. Open the public URL in your browser')\n",
        "    print('2. Upload an image')\n",
        "    print('3. Provide context description')\n",
        "    print('4. Click \"Process Image\"')\n",
        "    print('\\n‚èπÔ∏è  Press Ctrl+C to stop the server\\n')\n",
        "\n",
        "    # Display clickable link in Colab\n",
        "    display(HTML(f'<h2><a href=\"{public_url}\" target=\"_blank\">üîó Click here to open the service</a></h2>'))\n",
        "\n",
        "    # Run Flask app\n",
        "    app.run(port=port, debug=False, use_reloader=False)\n",
        "\n",
        "# --- CELL 13: Execute ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Note: Make sure to add your actual OCR implementation in the /api/correct route\n",
        "    print(\"‚ö†Ô∏è  IMPORTANT: You need to integrate your OCR implementation in the /api/correct route\")\n",
        "    print(\"    Look for the 'YOU NEED TO ADD YOUR OCR IMPLEMENTATION HERE' comment\\n\")\n",
        "\n",
        "    # Start the server\n",
        "    start_server()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}